{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TREBL Quick Start Example\n",
    "\n",
    "This notebook demonstrates a quick start workflow for TREBL analysis with:\n",
    "- **No error correction** (faster processing)\n",
    "- **Simple UMI deduplication only** (for Step 1 - TREBL experiment)\n",
    "\n",
    "This is ideal for initial data exploration or when processing time is a priority.\n",
    "\n",
    "**Note:** For large files, the plotting steps (`step1_reads_distribution`, `trebl_experiment_reads_distribution`) can be computationally intensive and may benefit from submission as a Savio job instead of running interactively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import glob\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import duckdb\n",
    "from tqdm import tqdm\n",
    "\n",
    "from trebl_tools import (\n",
    "    initial_map,\n",
    "    map_refiner,\n",
    "    complexity,\n",
    "    finder,\n",
    "    preprocess,\n",
    "    error_correct,\n",
    "    plotting,\n",
    "    umi_deduplicate,\n",
    "    pipelines\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Pipeline\n",
    "\n",
    "Key settings for quick start:\n",
    "- `error_correction=False` - Skips error correction for faster processing\n",
    "- `test_n_reads` - Optional: Set to a number (e.g., 100000) for testing with subset of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize pipeline with no error correction\n",
    "pipeline = pipelines.TreblPipeline(\n",
    "    db_path=\"quick_start.db\",\n",
    "    design_file_path=\"path/to/your/design_file.txt\",  # Update this path\n",
    "    error_correction=False,  # No error correction for quick start\n",
    "    output_path=\"output/quick_start\"\n",
    "    # test_n_reads=100000  # Uncomment to test with first 100k reads\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: TREBL Mapping\n",
    "\n",
    "Define barcodes and run initial mapping to establish barcode relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define barcodes to search for in reads\n",
    "AD = finder.Barcode(\n",
    "    name=\"AD\",\n",
    "    preceder=\"GGCTAGC\",\n",
    "    post=\"TGACTAG\",\n",
    "    length=120\n",
    ")\n",
    "\n",
    "AD_BC = finder.Barcode(\n",
    "    name=\"AD_BC\",\n",
    "    preceder=\"CGCGCC\",\n",
    "    post=\"GGGCCC\",\n",
    "    length=11\n",
    ")\n",
    "\n",
    "RT_BC = finder.Barcode(\n",
    "    name=\"RT_BC\",\n",
    "    preceder=\"CTCGAG\",\n",
    "    post=\"GGCCGC\",\n",
    "    length=14\n",
    ")\n",
    "\n",
    "# Combine barcodes\n",
    "bc_objects = [AD, AD_BC, RT_BC]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify sequencing file(s)\n",
    "step1_seq_file = \"path/to/your/step1_sequencing_file.fastq\"  # Update this path\n",
    "# Can be a single file (string) or multiple files (list of strings)\n",
    "# Supported formats: .fastq or .fastq.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot reads distribution\n",
    "# NOTE: For large files (>10M reads), consider submitting this as a Savio job\n",
    "# See examples/savio_jobs/quick_start_job.sh for job submission example\n",
    "\n",
    "pipeline.step1_reads_distribution(\n",
    "    seq_file=step1_seq_file,\n",
    "    bc_objects=bc_objects,\n",
    "    reverse_complement=True\n",
    ")\n",
    "# Produces histogram of reads per barcode\n",
    "# Helps pick appropriate reads_threshold for filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Step 1 mapping\n",
    "step1_map = pipeline.run_step_1(\n",
    "    seq_file=step1_seq_file,\n",
    "    bc_objects=bc_objects,\n",
    "    column_pairs=[(\"RT_BC\", \"AD\")],  # Check for collisions between RT_BC and AD\n",
    "    reads_threshold=10,  # Minimum reads to keep a barcode\n",
    "    reverse_complement=False\n",
    ")\n",
    "# Returns DataFrame of Step 1 mapping\n",
    "# Saves CSV, loss table visualization, and optional loss table CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TREBL Experiment with Simple UMI Deduplication\n",
    "\n",
    "Process the full TREBL experiment using simple UMI deduplication only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define UMI objects\n",
    "AD_UMI = finder.Barcode(\n",
    "    name=\"UMI\",\n",
    "    preceder=\"TGATTT\",\n",
    "    post=\"\",\n",
    "    length=12\n",
    ")\n",
    "\n",
    "RT_UMI = finder.Barcode(\n",
    "    name=\"UMI\",\n",
    "    preceder=\"TGTCAC\",\n",
    "    post=\"\",\n",
    "    length=12\n",
    ")\n",
    "\n",
    "# Separate barcode objects\n",
    "AD_bc_objects = [AD, AD_BC]  # AD and AD barcodes\n",
    "RT_bc_objects = [RT_BC]      # Reporter barcodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect sequencing files\n",
    "trebl_AD_seq_files = glob.glob(\"path/to/AD_assembled/*\")  # Update this path\n",
    "trebl_RT_seq_files = glob.glob(\"path/to/RT_assembled/*\")  # Update this path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot reads distribution for all files\n",
    "# NOTE: For large files, consider submitting this as a Savio job\n",
    "# See examples/savio_jobs/quick_start_job.sh for job submission example\n",
    "\n",
    "pipeline.trebl_experiment_reads_distribution(\n",
    "    AD_seq_files=trebl_AD_seq_files,\n",
    "    AD_bc_objects=AD_bc_objects,\n",
    "    RT_seq_files=trebl_RT_seq_files,\n",
    "    RT_bc_objects=RT_bc_objects,\n",
    "    reverse_complement=True\n",
    ")\n",
    "# Generates histograms for all AD and RT files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run TREBL experiment with SIMPLE UMI deduplication only\n",
    "trebl_results = pipeline.trebl_experiment_analysis(\n",
    "    AD_seq_files=trebl_AD_seq_files,\n",
    "    AD_bc_objects=AD_bc_objects,\n",
    "    RT_seq_files=trebl_RT_seq_files,\n",
    "    RT_bc_objects=RT_bc_objects,\n",
    "    reverse_complement=True,\n",
    "    step1_map_csv_path=\"output/quick_start/step1_AD_AD_BC_RT_BC_designed.csv\",  # Update with your step1 CSV path\n",
    "    AD_umi_object=AD_UMI,\n",
    "    RT_umi_object=RT_UMI,\n",
    "    umi_deduplication='simple'  # Use ONLY simple deduplication for quick start\n",
    ")\n",
    "\n",
    "# Access results\n",
    "AD_results = trebl_results[\"AD_results\"]\n",
    "RT_results = trebl_results[\"RT_results\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "After completing this quick start analysis:\n",
    "\n",
    "1. **Review outputs** in the `output/quick_start` directory\n",
    "2. **Check loss tables** to understand filtering at each step\n",
    "3. **Validate results** by examining the CSV files\n",
    "4. **For more comprehensive analysis**, see the `full_analysis_example.ipynb` notebook which includes:\n",
    "   - Error correction for improved accuracy\n",
    "   - Both simple and directional/complex UMI deduplication\n",
    "\n",
    "### Cleanup\n",
    "\n",
    "After analysis is complete, you can delete the DuckDB database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.remove(\"quick_start.db\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trebl_env",
   "language": "python",
   "name": "trebl_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
